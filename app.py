import streamlit as st
import requests
from bs4 import BeautifulSoup
import zipfile
import io
import time
import os
import math
import concurrent.futures

# ================= 1. é¡µé¢é…ç½® =================
st.set_page_config(
    page_title="å¾®ä¿¡æ–‡ç« å›¾ç‰‡æå–å™¨", 
    page_icon="âš¡",
    layout="centered"
)

# ================= 2. æ³¨å…¥ CSS =================
st.markdown("""
    <style>
        .block-container {
            padding-top: 2rem !important;
            padding-bottom: 1rem !important;
        }
        .stCheckbox {
            margin-top: 5px;
        }
        /* è°ƒæ•´åˆ†é¡µæŒ‰é’® */
        div[data-testid="column"] button {
            width: 100%;
        }
    </style>
""", unsafe_allow_html=True)

# ================= 3. åˆå§‹åŒ– Session State =================
if 'step' not in st.session_state:
    st.session_state.step = 1 
if 'scraped_images' not in st.session_state:
    st.session_state.scraped_images = []
if 'zip_buffer' not in st.session_state:
    st.session_state.zip_buffer = None
if 'current_page' not in st.session_state:
    st.session_state.current_page = 1

ITEMS_PER_PAGE = 12

# --- æµè§ˆå™¨ä¼ªè£…å¤´ (å…³é”®ä¿®å¤ï¼šå¿…é¡»ç”¨å®Œæ•´çš„é•¿å­—ç¬¦ä¸²) ---
# è¿™æ˜¯ä¹‹å‰èƒ½æˆåŠŸæŠ“å–çš„å…³é”®ï¼Œå¾®ä¿¡åªè®¤è¿™ä¸ª
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

# --- å…¨é€‰å›è°ƒ ---
def toggle_all():
    is_all_selected = st.session_state.select_all_key
    if 'scraped_images' in st.session_state:
        for i in range(len(st.session_state.scraped_images)):
            st.session_state[f"img_chk_{i}"] = is_all_selected

# --- ç¿»é¡µå›è°ƒ ---
def prev_page():
    if st.session_state.current_page > 1:
        st.session_state.current_page -= 1

def next_page():
    total_imgs = len(st.session_state.scraped_images)
    total_pages = math.ceil(total_imgs / ITEMS_PER_PAGE)
    if st.session_state.current_page < total_pages:
        st.session_state.current_page += 1

# --- å•å¼ å›¾ç‰‡ä¸‹è½½å‡½æ•° (å¤šçº¿ç¨‹ç”¨) ---
def download_one_image(img_info):
    index, url = img_info
    # æ ¼å¼ä¿®æ­£
    url = url.replace("/640?from=appmsg", "/640?from=appmsg&tp=jpg")
    url = url.replace("&tp=webp", "&tp=jpg")
    url = url.replace("wx_fmt=webp", "wx_fmt=jpg")
    try:
        # ä¸‹è½½æ—¶ä¹Ÿè¦å¸¦ä¸Š HEADERS
        r = requests.get(url, headers=HEADERS, timeout=10)
        if r.status_code == 200:
            return index, r.content
    except:
        pass
    return index, None

# ================= 4. ä¾§è¾¹æ  =================
with st.sidebar:
    st.header("ğŸ“– ä½¿ç”¨æ•™ç¨‹")
    st.markdown("""
    1. **è§£æ**ï¼šç²˜è´´é“¾æ¥ï¼Œç‚¹å‡»è§£æã€‚
    2. **é€‰æ‹©**ï¼šå‹¾é€‰å›¾ç‰‡ (âš¡å±€éƒ¨åˆ·æ–°)ã€‚
    3. **æ‰“åŒ…**ï¼šç‚¹å‡»ç”Ÿæˆ (ğŸš€å¤šçº¿ç¨‹ä¸‹è½½)ã€‚
    4. **ä¸‹è½½**ï¼šä¿å­˜ ZIP åŒ…ã€‚
    """)
    st.info("âœ… **å·²ä¿®å¤è§£æé—®é¢˜**\næ¢å¤å®Œæ•´ä¼ªè£…ï¼Œå‡†ç¡®æŠ“å–å›¾ç‰‡ï¼")
    st.markdown("---")
    st.caption("Made with â¤ï¸ TJH")

# ================= 5. ä¸»ç•Œé¢å¸ƒå±€ =================
col1, col2 = st.columns([1.2, 2], gap="medium")

with col1:
    if os.path.exists("heart_collage.png"):
        st.image("heart_collage.png", use_column_width=True)
    elif os.path.exists("heart_collage.jpg"):
        st.image("heart_collage.jpg", use_column_width=True)
    else:
        st.info("è¯·ä¸Šä¼ åä¸º heart_collage.png çš„å›¾ç‰‡")

with col2:
    st.markdown("## âš¡ å…¬ä¼—å·å›¾ç‰‡æå–")
    st.caption("æé€Ÿç‰ˆï¼šä¿®å¤æŠ“å–å¤±è´¥é—®é¢˜")
    st.markdown("---")
    
    url = st.text_input("ğŸ‘‡ åœ¨æ­¤ç²˜è´´é“¾æ¥:", placeholder="https://mp.weixin.qq.com/s/...", label_visibility="collapsed")
    
    if st.button("ğŸ” ç¬¬ä¸€æ­¥ï¼šè§£æå›¾ç‰‡", type="primary", use_container_width=True):
        if not url:
            st.warning("âš ï¸ è¯·å…ˆç²˜è´´é“¾æ¥ï¼")
        elif "mp.weixin.qq.com" not in url:
            st.error("âŒ é“¾æ¥æ ¼å¼ä¸å¯¹ã€‚")
        else:
            with st.spinner('æ­£åœ¨åˆ†æç½‘é¡µ...'):
                try:
                    # ä½¿ç”¨ä¿®å¤åçš„å®Œæ•´ HEADERS
                    resp = requests.get(url, headers=HEADERS, timeout=10)
                    resp.raise_for_status()
                    soup = BeautifulSoup(resp.text, 'html.parser')
                    content = soup.find(id="js_content")
                    if not content: content = soup
                    
                    imgs = content.find_all('img')
                    found_imgs = []
                    
                    for img in imgs:
                        src = img.get('data-src')
                        # ç¨å¾®æ”¾å®½è¿‡æ»¤æ¡ä»¶ï¼Œé˜²æ­¢æ¼æ‰å›¾ç‰‡
                        if src and len(src) > 10: 
                            found_imgs.append(src)
                    
                    if not found_imgs:
                        st.error("æœªæ‰¾åˆ°å›¾ç‰‡ï¼Œå¯èƒ½æ˜¯æ–‡ç« å·²åˆ é™¤æˆ–è¢«åŠ å¯†ã€‚")
                    else:
                        st.session_state.scraped_images = found_imgs
                        st.session_state.step = 2 
                        st.session_state.zip_buffer = None
                        st.session_state.current_page = 1
                        # é»˜è®¤å…¨é€‰
                        for i in range(len(found_imgs)):
                            st.session_state[f"img_chk_{i}"] = True
                        st.rerun()
                except Exception as e:
                    st.error(f"è§£æå¤±è´¥: {e}")

# ================= 6. æ ¸å¿ƒï¼šå±€éƒ¨åˆ·æ–°åŒºåŸŸ =================

@st.fragment
def show_gallery_area():
    if st.session_state.step >= 2 and st.session_state.scraped_images:
        st.divider()
        
        total_items = len(st.session_state.scraped_images)
        total_pages = math.ceil(total_items / ITEMS_PER_PAGE)
        current_p = st.session_state.current_page
        
        start_idx = (current_p - 1) * ITEMS_PER_PAGE
        end_idx = start_idx + ITEMS_PER_PAGE
        current_batch = st.session_state.scraped_images[start_idx:end_idx]
        
        st.subheader(f"ğŸ“¸ å…± {total_items} å¼  (ç¬¬ {current_p}/{total_pages} é¡µ)")
        
        # --- é¡¶éƒ¨æ§åˆ¶æ  ---
        c1, c2, c3, c4 = st.columns([1.5, 1, 1, 1])
        with c1:
            st.checkbox("å…¨é€‰ (æ‰€æœ‰é¡µ)", value=True, key="select_all_key", on_change=toggle_all)
        with c2:
            st.button("â¬…ï¸ ä¸Šä¸€é¡µ", on_click=prev_page, disabled=(current_p == 1), use_container_width=True)
        with c3:
            st.markdown(f"<div style='text-align: center; line-height: 2.5;'>{current_p} / {total_pages}</div>", unsafe_allow_html=True)
        with c4:
            st.button("ä¸‹ä¸€é¡µ â¡ï¸", on_click=next_page, disabled=(current_p == total_pages), use_container_width=True)

        # --- å›¾ç‰‡ç½‘æ ¼ ---
        with st.form("image_selection_form"):
            cols = st.columns(3)
            for i, img_url in enumerate(current_batch):
                global_index = start_idx + i
                col = cols[i % 3] 
                with col:
                    preview_url = img_url.replace("tp=webp", "tp=jpg")
                    st.markdown(
                        f'''<img src="{preview_url}" loading="lazy" style="width:100%; border-radius:8px; margin-bottom:5px; object-fit:cover; aspect-ratio: 1/1;" referrerpolicy="no-referrer">''', 
                        unsafe_allow_html=True
                    )
                    st.checkbox(f"å›¾ç‰‡ {global_index+1}", key=f"img_chk_{global_index}")
            
            st.markdown("---")
            submitted = st.form_submit_button("ğŸš€ ç”Ÿæˆå‹ç¼©åŒ… (æé€Ÿç‰ˆ)", type="primary", use_container_width=True)

            if submitted:
                selected_final_indices = []
                for i in range(total_items):
                    if st.session_state.get(f"img_chk_{i}", False):
                        selected_final_indices.append(i)
                
                if not selected_final_indices:
                    st.warning("âš ï¸ è¯·è‡³å°‘é€‰æ‹©ä¸€å¼ å›¾ç‰‡ï¼")
                else:
                    # --- å¤šçº¿ç¨‹ä¸‹è½½é€»è¾‘ ---
                    tasks = []
                    valid_urls = [st.session_state.scraped_images[i] for i in selected_final_indices]
                    
                    for idx, url in enumerate(valid_urls):
                        tasks.append((idx, url)) # è¿™é‡Œä¸ç”¨ä¼  headers äº†ï¼Œç›´æ¥ç”¨å…¨å±€çš„

                    zip_buffer = io.BytesIO()
                    total = len(tasks)
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    results = [None] * total
                    finished_count = 0
                    
                    # å¼€å¯8çº¿ç¨‹å¹¶å‘ä¸‹è½½
                    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
                        future_to_url = {executor.submit(download_one_image, task): task for task in tasks}
                        for future in concurrent.futures.as_completed(future_to_url):
                            idx, content = future.result()
                            if content:
                                results[idx] = content
                            finished_count += 1
                            progress_bar.progress(finished_count / total)
                            status_text.text(f"âš¡ æ­£åœ¨ä¸‹è½½: {finished_count}/{total} å¼ ...")

                    with zipfile.ZipFile(zip_buffer, "a", zipfile.ZIP_DEFLATED, False) as zf:
                        for i, content in enumerate(results):
                            if content:
                                zf.writestr(f"image_{i+1}.jpg", content)
                    
                    st.session_state.zip_buffer = zip_buffer
                    st.session_state.step = 3
                    st.rerun()

show_gallery_area()

# ================= 7. ä¸‹è½½æŒ‰é’® =================
if st.session_state.step == 3 and st.session_state.zip_buffer:
    st.balloons()
    st.success("âœ¨ æé€Ÿæ‰“åŒ…å®Œæˆï¼")
    
    st.download_button(
        label="ğŸ“¦ ç‚¹å‡»ä¸‹è½½ (ZIP)",
        data=st.session_state.zip_buffer.getvalue(),
        file_name="fast_images.zip",
        mime="application/zip",
        type="primary",
        use_container_width=True
    )
    
    if st.button("ğŸ”„ æå–å¦ä¸€ç¯‡æ–‡ç« "):
        st.session_state.step = 1
        st.session_state.scraped_images = []
        st.session_state.zip_buffer = None
        st.session_state.current_page = 1
        keys_to_remove = [k for k in st.session_state.keys() if k.startswith("img_chk_")]
        for k in keys_to_remove:
            del st.session_state[k]
        st.rerun()
